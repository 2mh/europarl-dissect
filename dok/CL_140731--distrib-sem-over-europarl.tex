%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% -*- coding: utf-8 -*-
\documentclass[11pt,twoside,openright]{mpreport}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french, english, ngerman]{babel}
\usepackage{pxfonts}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage[numbers]{natbib}
\usepackage{booktabs}
\usepackage{gb4e} %\noautomath % For linguistic examples %%%einfach muell
%\usepackage{listings}         % For listings %%%einfach muell
\usepackage{color} %%%einfach muell
\usepackage{hyperref}         % Hyperref should normally be the last
                              % package
\usepackage{qtree}
\usepackage{rotating}
\usepackage{url}
\usepackage{spverbatim}
\usepackage{float}
\usepackage{longtable}
\usepackage{newunicodechar}
\brokenpenalty10000\relax

\let\cleardoublepage\clearpage

% Information for the title page
\usepackage[type=seminar,
            seminar={Fragestellungen der statistikbasierten Semantik},
            semester={Frühlingssemester 2014}]{cluzh-title-cd2010}

% Avoid widows and orphans
\widowpenalty50000
\clubpenalty50000

% URL with access date
\newcommand{\urld}[2][???]{\url{#2} (\iflanguage{ngerman}{Letzter
    Abruf:}{accessed} #1)}

% Examples for the definition of convenience commands
\newcommand{\first}[1]{\emph{#1}}
\newcommand{\q}[1]{\iflanguage{ngerman}{\flqq#1\frqq}{``#1''}}
\newcommand{\gloss}[1]{`#1'}
\newcommand{\example}[1]{\emph{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Title page information
\title{Distributionelle Semantik über Europarl-Korpora
}
\author{Reto Baumgartner \and Hernani Marques}

\begin{document}
\maketitle
\small
\tableofcontents
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Einleitung}
\label{cha:einleitung}
Nach dem Gedanken der distributionellen Semantik ist jedes Wort durch sein Umfeld definiert. In diesem Fall ist der Range der Satz in beiden Sprachen. Da jeweils die Übersetzung den gleichen semantischen Inhalt hat, sollten sich die Umfeldwörter beider Sprachen einander angleichen und es ist egal in welcher Sprache das Umfeld geschrieben ist.\\
Durch eine Trennung der Matrix nach Sprache der einzelnen Vektoren -- die Vektordimensionen sind dabei dieselben -- kann man gezielt nach den ähnlichsten Wörtern für ein Beispielwort je nach gewünschter Sprache suchen. Damit bekommt man unter den ähnlichsten Wörtern verschiedene Übersetzungen für ein Wort und mit diesen auch ihre distributionell-semantische Definition als Vektor. Mit dem Vergleichen dieser Vektoren mit dem Vektor des Eingabesatzes können dann diejenigen Übersetzungen ausgewählt werden, die im aktuellen Kontext am angemessensten sind. Damit wird die Polysemie der Eingabewörter berücksichtigt.\\
Für die Restriktion der Dimensionen gibt es die Option der Lemmatisierung. Diese erlaubt es auch nur bestimmte Wortarten zu behandeln und das Resultat zu beeinflussen, falls die Wortarten nicht übereinstimmen. \\
Beim einsprachigen Verwenden des Programms unterbleibt die Unterscheidung der Matrizen in Sprachen und es werden innerhalb der gleichen Matrix die ähnlichsten Wörter zum Eingabewort gesucht.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Theoretische Basis}
\label{cha:theorie}
Der Kern des Projektes ist die Annahme, dass ein Wort durch sein Umfeld definiert wird und dass sich in parallelen Texten die Wörter und ihre Übersetzungen einander annähern. Widdows \citep[S. 190ff.]{geometry} hat dieses Verfahren verwendet um Übersetzungen zu Fachwörtern zu finden:
\begin{quote}
The main idea in building a bilingual WORDSPACE is to consider each document along with its translation as if they were a single 'compound' document. [...] Two words that occur in documents which are translations of one another can then be regarded as cooccurring, just as if they had occurred in the same monolingual document [...]. The corpus we used in our experiments was a collection of abstracts from German medical documents which are available with English translations.\\
This model allows a user to enter terms in \emph{either} language and finde related words or relevant documents in \emph{both} languages.
\end{quote}
Die Wörter nähern sich einander an und der Kontext eines Wortes sollte in diesem Gedanken sprachunabhängig werden.


Dinu et al. \cite{dissect} haben die Python-Bibliothek \textbf{DISSECT} entwickelt, die es einfach macht, in grossem Stil die ähnlichsten Wortvektoren zu einem bestimmten Vektor zu suchen. Durch die Möglichkeit mit grösseren Korpora zu arbeiten, können Ähnlichkeiten zwischen Wörtern berechnet werden:
\begin{quote}
Distributional methods for meaning similarity are based on the observation that similar words occur in similar contexts and measure similarity based on patterns of word occurrence in large corpora [...]. More precisely, they represent words, or any other target linguistic elements, as high-dimensional vectors, where the dimensions represent context features.\\
Semantic relatedness is assessed by comparing vectors, leading, for example, to determine that \emph{car} and \emph{vehicle} are very similar in meaning, since they have similar contextual distributions. Despite the appeal of these methods, modeling words in isolation has limited applications and ideally we want to model semantics beyond word level by representing the meaning of phrases or sentences.
\end{quote}

Die Möglichkeit zu einem Wort die semantischen Nachbarn zu finden, wie es uns durch DISSECT ermöglicht ist, nutzen wir für das Finden von Übersetzungskandidaten. In einem weiteren Schritt nutzen wir die Ähnlichkeitsmasse zwischen den Wörtern der einen Sprachen und denen der anderen Sprache. Dieses Mass verwenden wir in gewissem Sinn als Übersetzungsmodell.
Ein weiteres Ähnlichkeitsmass, also jenes zwischen den gefundenen Übersetzungskandidaten und dem Eingabesatz -- der semantisch auch dem Zielsatz entsprechen sollte -- nutzen wir in einer ähnlichen Weise wie das Sprachmodell in der konventionellen Statistikbasierten Maschinellen Übersetzung, ausser dass bei uns nur Schlüsse zur semantischer Komponente und nicht zu derjenigen der Wohlgeformtheit gezogen werden. Diese beiden Masse werden zu einem Score verrechnet, der die Sortierung nach den besten Kandidaten ermöglicht.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Praxis}
\label{cha:praxis}
\section{Aufbau des Inputs}
\label{sec:input}
Das Programm \verb+create_input_data.py+ berechnet aus einem zeilenweise alignierten parallelen Text am Beispiel des Sprachpaares Deutsch--Englisch folgende Dateien, die standardmässig im Ordner \verb+data/out+ erstellt werden:
\begin{itemize}
\item \verb+de-words.row+ enthält die Wörter des deutschen Textes in Kleinbuchstaben. Die Liste ist gefiltert nach Stoppwörtern:
\begin{verbatim}
kosovo-krieg_de
wiederaufnahme_de
bekannt_de
vorbildlicher_de
...
\end{verbatim}
\item \verb+en-words.row+ ist die entsprechende Liste für die englischen Wörter:
\begin{verbatim}
clean_en
based_en
possible_en
resumption_en
...
\end{verbatim}
\item \verb+de_en-words.col+ besteht aus dem Inhalt der vorherigen beiden Dateien. Diese Liste soll für alle verwendeten Matrizen eines Projektes die Vektordimensionen definieren:
\begin{verbatim}
kosovo-krieg_de
wiederaufnahme_de
bekannt_de
vorbildlicher_de
clean_en
based_en
possible_en
resumption_en
...
\end{verbatim}
\item \verb+en_en-de.sm+ ist die sparse Matrix, die die Wörter auf Englisch mit ihren Kontextwörtern in beiden Sprachen beinhält. Die dritte Stelle gibt an, wie oft sich die beiden Wörter begegnen. 
\begin{verbatim}
art_en war_en 4
war_en recognised_en 4
art_en krieg_de 4
based_en clean_en 1
...
\end{verbatim}
\item \verb+de_de-en.sm+ ist die entsprechende Matrix für die deutschen Wörter:
\begin{verbatim}
bekannt_de geschieht_de 1
krieg_de art_en 4
geschieht_de model_en 1
krieg_de model_en 4
...
\end{verbatim}
\end{itemize}
Die in den Dateien enthaltenen Terme sind jeweils mit einem Suffix \verb+_en+ oder \verb+_de+ versehen, der ihre Sprachzugehörigkeit markiert. Wenn mit
Lemmatisierung gearbeitet wird, besteht zusätzlich ein Infix mit den Zeichen \verb+_A+, \verb+_N+, \verb+_P+ oder \verb+_V+, welche Adjektive, Substantive,
Eigennamen oder Verben markieren.

Aus diesen Dateien werden die gepickelten\footnote{Die Daten werden für eine effizientere Verarbeitung mittels der Python-Bibliothek \textbf{pickle} als Python-Objekte gespeichert.} Dateien erstellt:
\begin{itemize}
\item \verb+de_de-en.pkl+ mit den Zeilen \verb+en-words.row+ und \\Spalten \verb+de_en-words.col+
\item \verb+en_en-de.pkl+ mit den Zeilen \verb+de-words.row+ und \\Spalten \verb+de_en-words.col+
\end{itemize}

Diese gepickelten Matrixdateien werden zusammen mit der Dimensionendatei \verb+de_en-words.col+ ans Programm \verb+besttranslations.py+ weitergegeben und dort eingelesen, bzw. beim Erstellen der Satzmatrix gebraucht.

Die Aufteilung der Wortvektoren in eine Matrix pro Sprache ist ein entscheidender Teil der Implementierung, da dadurch auf saubere Weise verhindert werden kann, dass Kandidaten in der ungewünschten Sprache durch DISSECT gefunden werden. In einem ersten Aufbau wurden ungewünschte Wörter nach Abgleich des Sprachtags bestraft, d.\,h. ihr Ähnlichkeitswert auf 0.0 gesetzt. Dabei bestand die Gefahr, dass für manche Wörter nur ungewünchte Wörter als die ähnlichsten
erschienen, die allesamt bestraft wurden. Dies hat darin resultiert, dass
keine Kandidaten vorgeschlagen werden konnten.

\section{Verwendung des Systems}
\label{sec:verwendung}
Unser Softwaresystem, das sich der DISSECT-Bibliothek bedient, ist
auf github öffentlich verfügbar:\\
\url{https://github.com/2mh/europarl-dissect}
\\
\\
Es besteht ein \verb+README+-File, welches über die konkreten 
Softwareanforderungen informiert, sowie (weitergehende) 
Verwendungsmöglichkeiten aufzeigt.
\\
\\
Die Programme sind stark parametrisierbar und es lassen sich die Sprachwahl, die zu verwendenden Dateien und auch Parameter zur Verarbeitung und zum Output als Argumente setzen.

In \verb+parameters.py+ lassen sich die Defaultwerte langfristig festlegen, wie zum Beispiel die Anzahl der Sätze, die zur Berechnung verwendet werden sollen oder die Anzahl der angezeigten Übersetzungen. Als brauchbar erwiesen sich während der Entwicklung:
\begin{itemize}
\item Die Bestrafung ungewünschter Wortarten, indem der Score mit 0.3 multipliziert wird\\
(\verb+DIFFERENT_POS_PUNISHMENT = 0.3+)
\item Das Suchen von jeweils 100 Übersetzungskandidaten für die Weiterverarbeitung\\
(\verb+NUMBER_OF_NEIGHBOURS = 100+)
\item Die Ausgabe der drei besten Übersetzungskandidaten\\
(\verb+NUMBER_OF_TRANSLATIONS = 3+)
\item Und eine dreifache Gewichtung der Ähnlichkeit zum Quellsprachesatz gegenüber der allgemeinen Ähnlichkeit (in etwa des Übersetzungsmodells)\\
(\verb+OVERALL_SIMILARITY_WEIGHT = 1+\\
\verb+SENTENCE_SIMILARITY_WEIGHT = 3+)
\end{itemize}

Die Anzahl der Trainingssätze und ob diese Daten lemmatisiert werden sollen, lässt sich auch als Argument (\verb+-l 1000+ für 1000 Sätze und \verb+-t+ für Lemmatisierung) dem Programm \verb+create_input_data.py+ mitgeben.

Das Ausgabeformat von \verb+besttranslations.py+ lässt sich im Programm selbst ändern. Ein minimaler Beispielsaufruf dieses Skripts sieht wie folgt aus:

\verb+python besttranslations.py -s en -t de -i <Inputdatei>+

oder für die Analyse über die Lemmata:

\verb+python besttranslations.py -l -s en -t de -i <Inputdatei>+

Dabei steht \verb+-l+ für \emph{Lemmatisierung}, \verb+-s en+ für die Quellsprache Englisch, \verb+-t de+ für die Zielsprache Deutsch und mit \verb+-i+ kann die Eingabedatei angegeben werden. Alternativ wäre es auch möglich die Eingabedatei wegzulassen und den zu analysierenden Text über die Standardeingabe zu senden.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Evaluation}
\label{cha:evaluation}

Dass die Evaluation semantischer Anwendungen grundsätzlich eine Schwierigkeit darstellen kann, zeigte sich auch hier in dem Mass, dass die Evaluation nicht automatisiert werden konnte und auf unser Sprachwissen als Bewerter in beiden Sprachen beruhte. Durch diese Einschränkung ist auch das Testset relativ klein und es ist möglich, dass sich dadurch Verzerrungen ergeben.

\section{Verwendung als Desambiguierungswerkzeug bei der Übersetzung}

Der Anteil der Inhaltswörter -- darunter fassen wir Verben, Substantive, Namen und Adjektive -- für die unter den Übersetzungsvorschlägen eine korrekte Option dabei war, war deutlich höher bei der Berechnung der Matrizen über den Oberflächenformen der Wörter. Entgegen der Erwartungen waren die Resultate beim lemmatisierten Input deutlich schlechter.

Ein weiteres Kriterium, das die Resultate beeinflusste, war die Grösse des Trainingskorpus. Bei sehr kleinen Mengen waren dabei die Werte tiefer als bei grösseren Mengen. Gerade bei der Oberflächenformbehandlung lässt sich dieses Spares-Data-Problem in der Tabelle unten erkennen.

Bei der lemmatisierten Verarbeitung dagegen sank die Qualität der Vorschläge deutlich mit zunehmender Datenmenge und gute Vorschläge kamen nur noch vereinzelt vor.

\begin{figure}[H]
\hspace{-6cm}\begin{tikzpicture}
    \begin{axis}[
        width  = 18cm,
        height = 8cm,
        major x tick style = transparent,
        ybar=2*\pgflinewidth,
        bar width=14pt,
        ymajorgrids = true,
        ylabel = {Gute Vorschläge (\%)},
        xlabel = {Trainingskorpus in Tausenden (k) Sätzen},
        symbolic x coords={150k,100k,50k,30k,20k,10k,5k},
        xtick = data,
        scaled y ticks = false,
        enlarge x limits=0.07, % balkenbreite
        ymin=0,
        legend cell align=left,
        legend style={
                at={(1,1.05)},
                anchor=south east,
                column sep=1ex
        }
    ]
        \addplot coordinates {(150k, 49.3) (100k,44) (50k,52) (30k,56) (20k,58.7) (10k,54.7) (5k,42.7)};%de-en surf
        \addplot coordinates {(150k, 5.3) (100k,13.3) (50k,14.3) (30k,12) (20k,16) (10k,17.3) (5k,16)};%de-en lemm

        \addplot coordinates {(150k, 65.6) (100k,67.2) (50k,64.1) (30k,71.9) (20k,70.3) (10k,64.1) (5k,57.8)};%en-de surf
        \addplot coordinates {(150k, 14.1) (100k,12.5) (50k,14.1) (30k,20.3) (20k,20.3) (10k,23.4) (5k,20.3)};%en-de lemm

        \legend{de$\rightarrow$en Oberflächenformen,de$\rightarrow$en Lemmatisierung,en$\rightarrow$de Oberflächenformen,en$\rightarrow$de Lemmatisierung}
    \end{axis}
\end{tikzpicture}
\caption{test}
\end{figure}

Als mögliche Erklärung der Unterschiede zwischen den verschiedenen Paarungen kamen wir auf die Idee, dass die Anzahl der verschiedenen Wörter, also der Types, einen Einfluss haben könnte. Je grösser die Trainingsdaten waren, umso grösser wurde das Verhältnis zwischen der Anzahl der Types in den jeweiligen Sprachen. Dass Deutsch mehr Types hat, lässt sich mit der Morphologie und vor allem der Möglichkeit Komposita zu bilden erklären. Es ist möglich, dass dieses Verhältnis je ungleicher es ist, schlechtere Resultate verursacht. Wie man in folgender
 Abbildung  erkennen kann, ist gerade bei lemmatisierten Trainingsdaten das 
Verhältnis besonders ungleich (also weit weg von 1) und die Resultate dort 
unbefriedigend.

\hspace{-6cm}\begin{tikzpicture}
    \begin{axis}[
        width  = 18cm,
        height = 8cm,
        major x tick style = transparent,
        ybar=2*\pgflinewidth,
        bar width=10pt,
        ymajorgrids = true,
        ylabel = {Anzahl Types (in Tausenden)},
        xlabel = {Trainingskorpus in Tausenden (k) Sätzen},
        symbolic x coords={150k,100k,50k,30k,20k,10k,5k},
        xtick = data,
        scaled y ticks = false,
        enlarge x limits=0.07, % balkenbreite
        ymin=0,
        legend cell align=left,
        legend style={
                at={(1,1.05)},
                anchor=south east,
                column sep=1ex
        }
    ]
        \addplot coordinates {(150k, 95.715) (100k,76.128) (50k,51.347) (30k,38.694) (20k,30.492) (10k,19.675) (5k,13.042)};% de surf
        \addplot coordinates {(150k, 41.096) (100k,33.889) (50k,24.760) (30k,19.741) (20k,16.217) (10k,11.460) (5k,8.100)};% en surf

        \addplot coordinates {(150k, 0) (100k, 0) (50k, 0) (30k,0) (20k,0) (10k,0) (5k,0)};% en surf

        \addplot coordinates {(150k, 38.763) (100k,32.658) (50k,23.878) (30k,19.034) (20k,15.598) (10k,10.839) (5k,7.461)};% de lemm
        \addplot coordinates {(150k, 11.760) (100k,10.363) (50k,8.269) (30k,6.955) (20k,5.938) (10k,4.490) (5k,3.306)};% en lemm

        \legend{DE-Types (Oberfläche), EN-Types (Oberfläche), ,DE-Types (Lemmata), EN-Types (Lemmata)} % Verhältnis-Zahl
    \end{axis}
\end{tikzpicture}

Während die Anzahl der Types grundsätzlich verschieden ist zwischen den Sprachen, gibt es mit der Oberflächenform in beiden Sprachen etwa gleich viele Wortpaarungen innerhalb der Sprache. In diesen Fällen waren auch die Übersetzungskandidaten besonders gut. Die Verhältnisse lassen sich der folgenden Tabelle entnehmen:

\hspace{-6cm}\begin{tikzpicture}
    \begin{axis}[
        width  = 18cm,
        height = 8cm,
        major x tick style = transparent,
        ybar=2*\pgflinewidth,
        bar width=10pt,
        ymajorgrids = true,
        ylabel = {Verhältnis},
        xlabel = {Trainingskorpus in Tausenden (k) Sätzen},
        symbolic x coords={150k,100k,50k,30k,20k,10k,5k},
        xtick = data,
        scaled y ticks = false,
        enlarge x limits=0.07, % balkenbreite
        ymin=0,
        legend cell align=left,
        legend style={
                at={(1,1.05)},
                anchor=south east,
                column sep=1ex
        }
    ]
        \addplot coordinates {(150k,2.32906) (100k,2.24639) (50k,2.07379) (30k,1.96008) (20k,1.88025) (10k,1.71684) (5k,1.61012)};% de-en ratio (s)
        \addplot coordinates {(150k,1.28995) (100k,1.23778) (50k,1.16061) (30k,1.12278) (20k,1.09667) (10k,1.02789) (5k,0.990561)};% de-de--en-en-ratio (s)
        \addplot coordinates {(150k,0) (100k,0) (50k,0) (30k,0) (20k,0) (10k,0) (5k,0)};% void
        \addplot coordinates {(150k,3.29617) (100k,3.1514) (50k,2.88765) (30k,2.73674) (20k,2.62681) (10k,2.41403) (5k,2.25681)};% de-en ratio (t)
        \addplot coordinates {(150k,3.16197) (100k,3.05025) (50k,2.88568) (30k,2.87985) (20k,2.8166) (10k,2.68355) (5k,2.65067)};% de-de--en-en-ratio (t)

        \legend{Verhältnis DE / EN (Oberfläche), Verhältnis DE-DE / EN-EN (Oberfläche),,Verhältnis DE / EN (Lemmata), Verhältnis DE-DE / EN-EN (Lemmata) }
    \end{axis}
\end{tikzpicture}

\paragraph{Übersetzungskandidaten EN--DE mit 30\,000 Trainingssätzen über Wortoberflächen\\\\}
In der Übersetzungsrichtung Englisch-Deutsch konnten die besten Resultate mit einem Trainingskorpus von 30\,000 Sätzen erreicht werden. Das Verhältnis zwischen Vorschlägen mit und ohne gute Kandidaten lässt sich der untenstehenden Tabelle entnehmen. Die Eingabewörter, für die keine gute Übersetzung gefunden wurde, sind dabei rot eingefärbt.

Hervorheben wollen wir dabei das Beispiel 'reports', das mit 'berichte' und 'berichten' übersetzt wurde. Beide verschiedenen Formen sind dabei relativ nahe am Eingangswort. Interessant wäre natürlich noch die Ähnlichkeit zwischen den beiden Vorschlägen, doch liesse sich diese wegen dem Satzkontext nicht direkt vergleichen.

Besonders ist auch das Beispiel 'welcomed', bei dem keiner der Vorschläge gut ist, jedoch die Vorschläge untereinander als hochgradig ähnlich bezeichnet werden können: 'präsidentin', 'präsident' und 'kommissionspräsident'. Man muss deshalb vermuten, dass die Semantik von 'welcomed' in diesem Beispiel verzerrt ist und das Wort im Korpus sehr oft im Zusammenhang mit Präsidenten verwendet wird.

\begin{table}[H]
\hspace{-4cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
sitting                 & sitzung (0.36) & 23.50 (0.29) & 00.05 (0.28) \\ %Y
\textcolor{red}{opened}                  & harmonisierungsamt (0.16) & beginn (0.11) & wurde (0.10) \\ % not quite
minutes                 & protokoll (0.38) & minuten (0.35) & abstimmungsergebnis (0.25) \\ %Y
\textcolor{red}{previous}                & vorredner (0.27) & wurde (0.16) & herr (0.14) \\ % wrong PoS 
sitting                 & vorangegangenen (0.40) & protokoll (0.38) & sitzung (0.37) \\ %Y
\textcolor{red}{were}                    & vorangegangenen (0.44) & protokoll (0.40) & genehmigt (0.39) \\
approved                & angenommen (0.21) & angenommenen (0.18) & wurde (0.15) \\ %Y
President               & präsident (0.31) & herr (0.30) & präsidentin (0.28) \\ %Y
\textcolor{red}{welcomed}                & präsidentin (0.26) & präsident (0.24) & kommissionspräsident (0.23) \\
adoption                & annahme (0.22) & hinblick (0.16) & betreffend (0.16) \\ %Y
\textcolor{red}{euro}                    & präsident (0.25) & duisenberg (0.21) & kollegen (0.21) \\
Latvia                  & lettland (0.25) & estland (0.22) & ostsee-anrainerstaaten (0.18) \\ %Y
January                 & 1. (0.42) & januar (0.40) & Übergangsbestimmungen (0.25) \\ %Y
expressed               & ausdruck (0.25) & zustimmung (0.22) & wurde (0.20) \\ %Y
Parliament              & parlament (0.36) & parlaments (0.35) & rechtzeitigen (0.26) \\ %Y
solidarity              & solidarität (0.38) & ausdruck (0.23) & mitgefühls (0.21) \\ %Y
victims                 & opfer (0.32) & ausdruck (0.22) & wurde (0.17) \\ %Y
storms                  & stürme (0.28) & sturm (0.18) & abgeordnete (0.14) \\ %Y
President               & herr (0.30) & präsident (0.30) & präsidentin (0.27) \\ %Y
\textcolor{red}{spoke}                   & präsidenten (0.32) & präsident (0.29) & präsidentin (0.27) \\
\textcolor{red}{UN}                      & abgeordnete (0.21) & darauf (0.20) & tun (0.20) \\
conference              & konferenz (0.31) & regierungskonferenz (0.29) & möchte (0.25) \\ %Y
\textcolor{red}{future}                  & darauf (0.23) & unsere (0.23) & ganz (0.23) \\
Syria                   & syrien (0.30) & volksabstimmungen (0.21) & präsident (0.21) \\ %Y
\textcolor{red}{open}                    & möchte (0.27) & ganz (0.23) & darauf (0.23) \\
Geneva                  & genfer (0.27) & genf (0.26) & jahrestag (0.24) \\ %Y
January                 & januar (0.30) & 1. (0.24) & möchte (0.23) \\ %Y
President               & herr (0.28) & präsident (0.27) & präsidentin (0.25) \\ %Y
\textcolor{red}{commented}               & zurückgehalten (0.32) & presseberichte (0.25) & berichte (0.22) \\ % wrong Pos
press                   & presse (0.22) & gemacht (0.19) & erklärt (0.18) \\ %Y
reports                 & berichte (0.29) & berichten (0.27) & präsidentin (0.26) \\ %Y
accusations             & vorwürfe (0.25) & anklägerin (0.19) & gewissenhafter (0.17) \\ %Y
made                    & kollegen (0.26) & frau (0.25) & gemacht (0.24) \\ %Y
Romanian                & rumänischen (0.25) & vorwürfe (0.19) & liliana (0.15) \\ %Y
Prime                   & premierminister (0.37) & ministerpräsidenten (0.29) & präsidentin (0.25) \\ %Y
Minister                & premierminister (0.40) & ministerpräsident (0.30) & ministerpräsidenten (0.29) \\ %Y
Victor                  & victor (0.22) & emmanuel (0.21) & steuereintreibers (0.14) \\ %Y
\textcolor{red}{Ponta}                   & premierminister (0.37) & zurückgehalten (0.31) & ministerpräsident (0.28) \\
Elmar                   & elmar (0.26) & präsident (0.22) & präsidentin (0.21) \\ %Y
Brok                    & brok (0.27) & präsident (0.27) & elmar (0.25) \\ %Y
deadline                & termin (0.19) & grundsatzabkommen (0.17) & frist (0.17) \\ %Y
tabling                 & interpretiert. (0.14) & vorlage (0.13) & us-regierung (0.12) \\ %Y (vorlage: good!)
amendments              & Änderungsanträge (0.31) & Änderungsanträgen (0.30) & eingebrachten (0.26) \\ %Y
\textcolor{red}{was}                     & 12 (0.30) & Änderungsanträge (0.29) & 14 (0.28) \\
\textcolor{red}{set}                     & wurden (0.21) & ansicht (0.20) & betrifft (0.19) \\
Tuesday                 & dienstag (0.27) & schlagzeile (0.16) & herald (0.16) \\ %Y
January                 & januar (0.29) & 26. (0.21) & 1. (0.21) \\ %Y
noon                    & 12.00 (0.32) & 12 (0.29) & findet (0.25) \\ %Y
vote                    & abstimmung (0.36) & bitte (0.26) & findet (0.25) \\ %Y
\textcolor{red}{be}                      & 12.00 (0.34) & abstimmung (0.34) & verlegen (0.34) \\
held                    & möchte (0.25) & übrigen (0.21) & halten (0.20) \\ %Y
Wednesday               & mittwoch (0.36) & abstimmung (0.33) & bitte (0.24) \\ %Y
January                 & januar (0.33) & 1. (0.24) & 15. (0.22) \\ %Y
noon                    & 12.00 (0.44) & abstimmung (0.43) & findet (0.37) \\ %Y
\textcolor{red}{appointments}            & wäre (0.26) & durchgefallen (0.23) & verpuffen (0.23) \\
be                      & minuten (0.32) & wäre (0.30) & wären (0.26) \\ %Y
\textcolor{red}{deemed}                  & instrumentalisiert (0.17) & kriegsgerät (0.16) & kaste (0.16) \\
ratified                & ratifiziert (0.27) & ratifizierung (0.18) & symbolhafte (0.18) \\ %Y
were                    & minuten (0.32) & wäre (0.30) & wären (0.26) \\ %Y (good!)
\textcolor{red}{objections}              & hätte (0.23) & könnte. (0.22) & wertpapierdienstleistungen (0.21) \\
approval                & hätte (0.26) & möchte (0.22) & zustimmung (0.21) \\ %Y
minutes                 & minuten (0.32) & protokoll (0.28) & hätte (0.23) \\ %Y
\textcolor{red}{item}                    & folgt (0.34) & tagesordnung (0.29) & anfragen: (0.29) \\ % not quite
closed                  & geschlossen (0.47) & 1999-2000 (0.31) & 19.40 (0.31) \\ %Y
\hline
\end{tabular}\end{footnotesize}\\
\caption{Beste Übersetzungskandidaten EN--DE (30k, Wortoberflächen)}
\end{table}



%%%
\paragraph{Übersetzungskandidaten DE--EN mit 20\,000 Trainingssätzen über Wortoberflächen\\\\}
Nicht besonders anders sehen die Resultate in die umgekehrte Übersetzungsrichtung aus. Hier war das Trainingsset mit 20\,000 die Basis für die besten Ergebnisse (vgl. nachfolgende Tabelle).
\label{sec:evalDeEn10kSurf}
\hspace{-4cm}
\begin{table}[H]
\caption{Beste Übersetzungskandidaten DE--EN (20k, Wortoberflächen)}
\begin{scriptsize}
\begin{tabular}{|llll|}
\hline
Sitzung                 & sitting (0.54) & suspended (0.52) & 11.50 (0.51) \\ %Y
\textcolor{red}{wird}                    & sitting (0.59) & 11.50 (0.54) & suspended (0.53) \\
Uhr                     & p.m (0.52) & sitting (0.48) & p.m. (0.47) \\ %Y
\textcolor{red}{eröffnet}               & maximised (0.14) & orwell (0.14) & depicted (0.14) \\
\textcolor{red}{Protokoll}               & minutes (0.48) & sitting (0.40) & distributed (0.27) \\
vorangegangenen         & sitting (0.38) & distributed (0.22) & previous (0.21) \\ %Y
Sitzung                 & sitting (0.40) & 11.50 (0.28) & 8.25 (0.26) \\ %Y
\textcolor{red}{wird}                    & minutes (0.53) & sitting (0.41) & 11.50 (0.23) \\
\textcolor{red}{genehmigt}               & minutes (0.45) & sitting (0.34) & distributed (0.21) \\
Präsident              & president (0.27) & ladies (0.26) & congratulating (0.24) \\ %Y
begrüßt               & welcomes (0.27) & gave (0.15) & presented (0.15) \\ %Y
Einführung             & euro (0.42) & introduction (0.33) & introducing (0.19) \\ %Y
Euro                    & euro (0.40) & eur (0.30) & 1 (0.25) \\ %Y
Währung                & currency (0.31) & monetary (0.25) & 2496/96/ecsc (0.19) \\ %Y
\textcolor{red}{Lettland}                & euro (0.43) & january (0.39) & introduction (0.30) \\
1.                      & january (0.44) & euro (0.38) & 1 (0.27) \\ %Y
Januar                  & january (0.40) & euros (0.25) & 1 (0.24) \\ %Y
\textcolor{red}{2014.}                   & euro (0.43) & january (0.39) & introduction (0.30) \\
\textcolor{red}{spricht}                 & within (0.21) & union (0.20) & people (0.20) \\
\textcolor{red}{Opfern}                  & european (0.27) & within (0.16) & union (0.16) \\
Unwetter                & belongings (0.21) & possessions (0.18) & weather (0.17) \\ %Y
Solidarität            & solidarity (0.38) & union (0.20) & within (0.19) \\ %Y
Europäischen           & european (0.34) & union (0.31) & parliament (0.27) \\ %Y
Parlaments              & parliament (0.25) & cod (0.24) & establishing (0.23) \\ %Y
Präsident              & ladies (0.24) & president (0.24) & gentlemen (0.22) \\ %Y
\textcolor{red}{erinnert}                & whose (0.22) & one (0.15) & order (0.15) \\
Konferenz               & presidents (0.25) & conference (0.18) & held (0.16) \\ %Y
Vereinten               & nations (0.39) & united (0.24) & bangkok (0.23) \\ %Y
Nationen                & nations (0.34) & united (0.22) & bangkok (0.21) \\ %Y
Zukunft                 & future (0.24) & present (0.14) & one (0.13) \\ %Y
\textcolor{red}{Syriens}                 & nations (0.25) & damascus (0.20) & assad (0.19) \\
\textcolor{red}{Eröffnung}              & conference (0.20) & intergovernmental (0.14) & present (0.13) \\
\textcolor{red}{22.}                     & bodyguard (0.18) & vizcaya (0.18) & jorge (0.16) \\
Januar                  & january (0.27) & scheduled (0.16) & standardisation (0.14) \\ %Y
Genf                    & geneva (0.25) & held (0.13) & rights (0.13) \\ %Y
\textcolor{red}{anberaumt}               & nations (0.29) & tenth (0.24) & ta (0.22) \\
\textcolor{red}{ist}                     & nations (0.29) & tenth (0.24) & ta (0.22) \\
Präsident              & brok (0.27) & president (0.27) & ladies (0.26) \\ %Y
\textcolor{red}{weist}                   & upswing (0.20) & proceeded (0.20) & karl (0.17) \\
\textcolor{red}{Pressemeldungen}         & brok (0.20) & elmar (0.19) & upswing (0.18) \\
Vorwürfe               & accusations (0.18) & scrupulously (0.12) & question. (0.09) \\ %Y
\textcolor{red}{rumänische}             & brok (0.20) & elmar (0.19) & upswing (0.18) \\
Premierminister         & prime (0.20) & animosities (0.16) & hatreds (0.16) \\ %Y
\textcolor{red}{Victor}                  & brok (0.20) & elmar (0.19) & upswing (0.18) \\
\textcolor{red}{Ponta}                   & brok (0.20) & elmar (0.19) & upswing (0.18) \\
Elmar                   & brok (0.29) & elmar (0.29) & tsatsos (0.29) \\ %Y
Brok                    & brok (0.31) & tsatsos (0.25) & a5-0029/2000 (0.18) \\ %Y
erhoben                 & one (0.11) & great (0.11) & brought (0.10) \\ %Y (brought up)
\textcolor{red}{hat}                     & brok (0.20) & elmar (0.19) & upswing (0.18) \\
Frist                   & deadline (0.17) & 2034 (0.17) & take (0.13) \\ %Y
Einreichung             & backdate (0.08) & submitting (0.08) & submission (0.08) \\ %Y
\textcolor{red}{Änderungsanträgen}     & nos (0.21) & debtor (0.20) & 14 (0.16) \\
\textcolor{red}{wird}                    & p.m. (0.25) & noon (0.24) & p.m (0.24) \\
Dienstag                & tuesday (0.24) & submission (0.14) & one-way (0.11) \\ %Y
14.                     & january (0.23) & 14 (0.18) & february (0.16) \\ %Y
Januar                  & january (0.28) & 2002 (0.12) & scheduled (0.12) \\ %Y
Uhr                     & p.m (0.34) & noon (0.31) & p.m. (0.27) \\ %Y
\textcolor{red}{festgesetzt}             & pinpointing (0.15) & prisoner (0.15) & legislated (0.14) \\ % not quite
\textcolor{red}{Abstimmung}              & noon (0.66) & 12.00 (0.59) & a.m (0.53) \\
\textcolor{red}{findet}                  & noon (0.66) & 12.00 (0.59) & a.m (0.55) \\
Mittwoch                & wednesday (0.29) & take (0.22) & request (0.14) \\ %Y
\textcolor{red}{15.}                     & january (0.23) & resigned (0.13) & instead (0.12) \\
Januar                  & january (0.30) & take (0.21) & 2002 (0.12) \\ %Y
Uhr                     & noon (0.61) & 12.00 (0.54) & p.m (0.53) \\ %Y
\textcolor{red}{Benennungen}             & contradiction (0.24) & stark (0.16) & confirmed (0.15) \\
gelten                  & apply (0.15) & legislation (0.11) & fundamental (0.11) \\ %Y
bestätigt              & confirmed (0.19) & confirms (0.15) & apply (0.13) \\ %Y
Genehmigung             & approval (0.14) & minutes (0.14) & sitting (0.13) \\ %Y
\textcolor{red}{vorliegenden}            & draft (0.14) & one (0.13) & concerning (0.13) \\
Protokolls              & protocol (0.16) & methodology (0.16) & ratios (0.15) \\ %Y
Widerspruch             & contradiction (0.27) & law (0.12) & policies (0.12) \\ %Y
\textcolor{red}{eingeht}                 & platitudes (0.22) & tired (0.22) & cement (0.20) \\
Punkt                   & point (0.30) & matter (0.16) & order (0.16) \\ %Y
\textcolor{red}{ist}                     & leopards (0.50) & closed (0.46) & 8.25 (0.29) \\
geschlossen             & closed (0.43) & 8.25 (0.30) & 11.10 (0.30) \\ %Y
\hline
\end{tabular}
\end{scriptsize}
\end{table}


\section{Innerhalb einer Sprache}
Die folgenden Beispiele zeigen, was passiert, wenn man innerhalb einer Sprache probiert zu ``übersetzen''. Für die Semantik wurden die gleiche Art von Matrizen verwendet wie bei den zweisprachigen Versuchen, jedoch wurde für die Ausgangs- und Zielsprache -- die ja gleich sind -- dieselbe Matrix verwendet. Von einer Arbeitsweise rein in einer Sprache unterscheidet sich dieses Verfahren nur darin, dass in den Vektordimensionen noch die Wörter der anderen Sprache auftauchen. Der Einfluss sollte sich gering halten und es könnte höchstens erwartet werden, dass satzabhängige ähnliche Wörter gefunden werden.
\paragraph{Englisch mit Oberflächenform (10\,000 Trainingssätze)\\\\}
\begin{table}[H]
\hspace{-0cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
The & & & \\
sitting                 & 8.40 (0.32) & 11.15 (0.32) & 8.14 (0.32) \\
opened                  & opened (0.25) & bosnia (0.19) & serbia (0.19) \\
at & & & \\
17.05 & & & \\
. & & & \\
The & & & \\
minutes                 & minutes (0.27) & sitting (0.21) & distributed (0.18) \\
of & & & \\
the & & & \\
previous                & previous (0.28) & speakers (0.17) & period (0.15) \\
sitting                 & sitting (0.38) & 8.40 (0.25) & 11.15 (0.25) \\
were                    & 8.40 (0.20) & 11.15 (0.20) & 8.14 (0.20) \\
approved                & approved (0.28) & adopted (0.17) & commission (0.16) \\
. & & & \\
The & & & \\
President               & ladies (0.28) & prodi (0.28) & reformist (0.28) \\
welcomed                & welcomed (0.28) & cut (0.18) & anti-racist (0.18) \\
the & & & \\
adoption                & adoption (0.29) & featuring (0.16) & nana (0.16) \\
of & & & \\
the & & & \\
euro                    & euro (0.30) & dollar (0.26) & interventionism (0.19) \\
by & & & \\
Latvia                  & inspiring (0.17) & surety (0.17) & re-read (0.17) \\
on & & & \\
1 & & & \\
January                 & january (0.33) & standardisation (0.19) & constructed (0.18) \\
2014. & & & \\
\hline
\end{tabular}\end{footnotesize}
\caption{Kandidaten EN (10k, Worteroberflächen)}
\end{table}

Grosse Beachtung verdienen auch die verschiedenen Vorschläge für 'sitting': Einmal wurde korrekt wieder auf 'sitting' verwiesen mit Zahlausdrücken als Alternative, das andere Mal kamen nur die Zahlausdrücke.

Auch wenn sie hier nicht passen sind die Vorschläge 'serbia' und 'bosnia' interessant in ihrem gemeinsamen Vorkommen. Als gewünscht kann man die Alternative 'dollar' zu 'euro' bezeichnen, wo beide klar semantisch dem gleichen Feld angehören.

\paragraph{Englisch mit Lemmatisierung (10\,000 Trainingssätze)\\\\}
Wird mit Lemmatisierung gearbeitet, so resultieren beim ersten  Satz gute Vorschläge, der Rest jedoch enttäuscht, wie die Tabelle zeigt:
\begin{table}[H]
\hspace{-0cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
The & & & \\
sitting                 & sitting (0.08) & anniversary (0.05) & declaration (0.05) \\
opened                  & open (0.08) & way (0.06) & go (0.06) \\
at & & & \\
17.05 & & & \\
. & & & \\
The & & & \\
minutes                 & go (0.12) & hold (0.12) & use (0.12) \\
of & & & \\
the & & & \\
previous                & pump (0.12) & squeeze (0.12) & distribute (0.12) \\
sitting                 & distribute (0.12) & go (0.11) & use (0.11) \\
were                    & concern (0.15) & something (0.15) & go (0.15) \\
approved                & concern (0.15) & something (0.14) & go (0.14) \\
. & & & \\
The & & & \\
President               & ending (0.07) & this (0.05) & noire (0.05) \\
welcomed                & welcome (0.08) & fact (0.05) & s (0.05) \\
the & & & \\
adoption                & adoption (0.08) & fact (0.06) & adopt (0.05) \\
of & & & \\
the & & & \\
euro                    & ending (0.07) & this (0.05) & noire (0.05) \\
by & & & \\
Latvia                  & ending (0.07) & this (0.05) & noire (0.05) \\
on & & & \\
1 & & & \\
January                 & ending (0.07) & this (0.05) & noire (0.05) \\
2014. & & & \\
\hline
\end{tabular}\end{footnotesize}
\caption{Kandidaten EN (10k, Lemmata)}
\end{table}
Man kann sicherlich sagen, dass durch die Lemmatisierung die Relation von Wörtern zu ihrem Umfeld verloren gehen kann -- mehr als bei den Oberflächenformen -- und die Verarbeitung mehr einem Bag-of-words ähnelt. Dies reicht aber nicht zur Erklärung, wieso besonders der letzte Satz ein derart schlechtes Resultat brachte.

\paragraph{Deutsch mit Oberflächenform (10\,000 Trainingssätze)\\\\}
\begin{table}[H]
\hspace{-4.5cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
Die & & & \\
Sitzung                 & sitzung (0.38) & 13.05 (0.35) & 19.50 (0.35) \\
wird                    & 13.05 (0.31) & 19.50 (0.31) & 17.30 (0.29) \\
um & & & \\
17.05 & & & \\
Uhr                     & 12.00 (0.38) & 13.05 (0.32) & 19.50 (0.32) \\
eröffnet               & eröffnet (0.25) & billigen (0.22) & tätigkeitsfeld (0.19) \\
. & & & \\
Das & & & \\
Protokoll               & protokoll (0.32) & protokolls (0.26) & montreal (0.19) \\
der & & & \\
vorangegangenen         & vorangegangenen (0.31) & mindestdauer (0.22) & erhoffe (0.22) \\
Sitzung                 & sitzung (0.25) & protokolls (0.23) & genehmigung (0.17) \\
wird                    & protokolls (0.21) & wiedergegeben (0.16) & genehmigung (0.16) \\
genehmigt               & genehmigt (0.30) & abgefaßt (0.23) & stahlunternehmen (0.21) \\
. & & & \\
Der & & & \\
Präsident              & herr (0.33) & präsident (0.26) & kollegen (0.23) \\
begrüßt               & begrüßt (0.25) & herr (0.19) & demokraten (0.15) \\
die & & & \\
Einführung             & einführung (0.28) & wirtschaft (0.15) & wurde (0.15) \\
des & & & \\
Euro                    & euro (0.27) & milliarden (0.24) & millionen (0.24) \\
als & & & \\
Währung                & währung (0.27) & wirtschaft (0.21) & a5-0073/1999 (0.20) \\
in & & & \\
Lettland                & Übergangsbestimmungen (0.22) & entschiedenheit (0.17) & geldfälschung (0.14) \\
am & & & \\
1.                      & 1. (0.33) & Übergangsbestimmungen (0.28) & programmvorlage (0.19) \\
Januar                  & januar (0.25) & Übergangsbestimmungen (0.24) & 1. (0.23) \\
2014.                   & Übergangsbestimmungen (0.22) & entschiedenheit (0.17) & geldfälschung (0.14) \\
\hline
\end{tabular}\end{footnotesize}
\caption{Kandidaten DE (10k, Wortoberflächen)}
\end{table}

Hier sind im Grossen und Ganzen gute Vorschläge zu finden. Das Trippel aus 'euro', 'milliarden' und 'millionen' zeigt, dass auch semantisch ähnliche Wörter gefunden werden können. Schön ist auch dass wie mit 'protokoll' und 'protokolls' Formen des gleichen Wortes gefunden werden konnten. Das könnte bedeuten, dass sich auch die verschiedenen Formen eines Wortes annähern.

\paragraph{Deutsch mit Lemmatisierung (10\,000 Trainingssätze)\\\\}
\begin{table}[H]
\hspace{-2.7cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
Die & & & \\
Sitzung                 & sitzung (0.13) & durchführen (0.10) & Änderungsantrag (0.10) \\
wird                    & müssen (0.10) & schnell (0.10) & dürfen (0.10) \\
um & & & \\
17.05 & & & \\
Uhr                     & sitzung (0.09) & uhr (0.09) & unterbrechen (0.08) \\
eröffnet               & eröffnen (0.09) & aufnehmen (0.09) & einsetzen (0.09) \\
. & & & \\
Das & & & \\
Protokoll               & protokoll (0.13) & aufnehmen (0.09) & Änderungsantrag (0.09) \\
der & & & \\
vorangegangenen         & vorangegangen (0.11) & durchführen (0.09) & Änderungsantrag (0.09) \\
Sitzung                 & sitzung (0.11) & durchführen (0.10) & aufnehmen (0.09) \\
wird                    & müssen (0.10) & schnell (0.10) & dürfen (0.10) \\
genehmigt               & genehmigen (0.09) & müssen (0.08) & dürfen (0.08) \\
. & & & \\
Der & & & \\
Präsident              & herr (0.10) & präsident (0.08) & kommissar (0.07) \\
begrüßt               & herr (0.08) & begrüßen (0.08) & fraktion (0.07) \\
die & & & \\
Einführung             & einführung (0.08) & kommission (0.07) & weit (0.07) \\
des & & & \\
Euro                    & million (0.09) & euro (0.08) & gering (0.07) \\
als & & & \\
Währung                & währung (0.08) & wirtschaft (0.07) & einführung (0.06) \\
in & & & \\
Lettland                & Übergangsbestimmung (0.10) & gesamtumfang (0.06) & entschiedenheit (0.05) \\
am & & & \\
1.                      & 1. (0.10) & januar (0.06) & jahr (0.06) \\
Januar                  & januar (0.08) & kommission (0.07) & erst (0.07) \\
2014.                   & Übergangsbestimmung (0.10) & gesamtumfang (0.06) & entschiedenheit (0.05) \\
\hline
\end{tabular}\end{footnotesize}
\label{Kandidaten DE (10k, Lemmata)}
\end{table}

Mit Deutsch als Ausgangs- und Zielsprache ist die Lemmatisierung nicht ein solches Hindernis, wie auf Englisch. Deutlich mehr Vorschläge lassen sich mit semantischen Feldern erklären und die Grundform des Wortes erscheint auch oft in den ersten beiden Vorschlägen.

Interessant ist auch der Zusammenhang zwischen 'werden' und 'müssen'. Beide kommen als Hilfs- bzw. als Modalverb in einem ähnlichen Zusammenhang vor und durch die Lemmatisierung geht ihre Restriktion der untergeordneten Verbform verloren. Sie können wirklich als ähnlich bezeichnet werden.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Schluss}
\label{cha:schluss}

sehr häppy. es klappt. 

speziell: lemmatisierung. für englisch offenbar nicht gut. (wortarten bleiben erhalten, was macht es also bei englisch für einen unterschied?

smoothing?


Als Mögliche Gebiete zur Weiterarbeit stehen sicherlich einmal die Wahl der Sprachen zur Verfügung, wobei es interessant wäre mit zwei einander sehr ähnlichen Sprachen, und die Wahl der Textdomäne.

Vorstellbar ist auch eine Optimierung, bei der Wörter, die nur einmal auftreten gar nicht in die Wortvektordimensionen aufgenommen werden, wodurch sich die Matrix sicherlich in eine Dimension verkleinern würde.

Aktuellere Optimierungen in der distributionellen Semantik wie die Restriktion des Umfeldes auf gewisse grammatische oder thematische Funktionen erscheinen hier deutlich komplizierter, da dies eine gute Alignierung auf der Wortebene verlangen würde und nicht ganz klar wäre, wie die Relationen sich über die Sprachgrenze verhalten müssten.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plain-de}     % For German
\bibliography{seminar}
\addcontentsline{toc}{chapter}{Literaturverzeichnis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\listoffigures
%\addcontentsline{toc}{chapter}{Abbildungsverzeichnis}
\end{document}

% TODO:
% README einbinden
% erklaeren, wie man korpora einbindet
% schlusswort
