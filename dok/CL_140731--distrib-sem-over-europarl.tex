%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% -*- coding: utf-8 -*-
\documentclass[11pt,twoside,openright]{mpreport}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french, english, ngerman]{babel}
\usepackage{pxfonts}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage[numbers]{natbib}
\usepackage{booktabs}
\usepackage{gb4e} %\noautomath % For linguistic examples %%%einfach muell
%\usepackage{listings}         % For listings %%%einfach muell
%\usepackage{color} %%%einfach muell
\usepackage{hyperref}         % Hyperref should normally be the last
                              % package
\usepackage{qtree}
\usepackage{rotating}
\usepackage{url}
\usepackage{spverbatim}
\usepackage{float}
\usepackage{longtable}
\usepackage{newunicodechar}
\brokenpenalty10000\relax

\let\cleardoublepage\clearpage

% Information for the title page
\usepackage[type=seminar,
            seminar={Fragestellungen der statistikbasierten Semantik},
            semester={Frühlingssemester 2014}]{cluzh-title-cd2010}

% Avoid widows and orphans
\widowpenalty50000
\clubpenalty50000

% URL with access date
\newcommand{\urld}[2][???]{\url{#2} (\iflanguage{ngerman}{Letzter
    Abruf:}{accessed} #1)}

% Examples for the definition of convenience commands
\newcommand{\first}[1]{\emph{#1}}
\newcommand{\q}[1]{\iflanguage{ngerman}{\flqq#1\frqq}{``#1''}}
\newcommand{\gloss}[1]{`#1'}
\newcommand{\example}[1]{\emph{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Title page information
\title{Distributionelle Semantik über Europarl-Korpora
}
\author{Reto Baumgartner \and Hernani Marques}

\begin{document}
\maketitle
\small
\tableofcontents
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Einleitung}
\label{cha:einleitung}
Nach dem Gedanken der distributionellen Semantik ist jedes Wort durch sein Umfeld definiert. In diesem Fall ist der Range der Satz in beiden Sprachen. Da jeweils die Übersetzung den gleichen semantischen Inhalt hat, sollten sich die Umfeldwörter beider Sprachen einander angleichen und es ist egal in welcher Sprache das Umfeld geschrieben ist.\\
Durch eine Trennung der Matrix nach Sprache der einzelnen Vektoren -- die Vektordimensionen sind dabei dieselben -- kann man gezielt nach den ähnlichsten Wörtern für ein Beispielwort je nach gewünschter Sprache suchen. Damit bekommt man unter den ähnlichsten Wörtern verschiedene Übersetzungen für ein Wort und mit diesen auch ihre distributionell-semantische Definition als Vektor. Mit dem Vergleichen dieser Vektoren mit dem Vektor des Eingabesatzes können dann diejenigen Übersetzungen ausgewählt werden, die im aktuellen Kontext am angemessensten sind. Damit wird die Polysemie der Eingabewörter berücksichtigt.\\
Für die Restriktion der Dimensionen gibt es die Option der Lemmatisierung. Diese erlaubt es auch nur bestimmte Wortarten zu behandeln und das Resultat zu beeinflussen, falls die Wortarten nicht übereinstimmen. \\
Beim einsprachingen Verwenden des Programms unterbleibt die Unterschiedung der Matrizen in Sprachen und es werden innerhalb der gleichen Matrix die ähnlichsten Wörter zum Eingabewort gesucht.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Theoretische Basis}
\label{cha:theorie}
Der Kern des Projektes ist die Annahme, dass ein Wort durch sein Umfeld definiert wird und dass sich in parallelen Texten die Wörter und ihre Übersetzungen einander annähern. Widdows \citep[S. 190ff.]{geometry} hat dieses Verfahren verwendet um Übersetzungen zu Fachwörtern zu finden:
\begin{quote}
The main idea in building a bilingual WORDSPACE is to consider each document along with its translation as if they were a single 'compound' document. [...] Two words that occur in documents which are translations of one another can then be regarded as cooccurring, just as if they had occurred in the same monolingual document [...]. The corpus we used in our experiments was a collection of abstracts from German medical documents which are available with English translations.\\
This model allows a user to enter terms in \emph{either} language and finde related words or relevant documents in \emph{both} languages.
\end{quote}
Die Wörter nähern sich einander an und der Kontext eines Wortes sollte in diesem Gedanken sprachunabhängig werden.


Dinu et al. \cite{dissect} haben ein Tool entwickelt, das es einfach macht, in grossem Stil die ähnlichsten Wortvektoren zu einem bestimmten Vektor zu suchen. Durch die Möglichkeit mit grösseren Korpora zu arbeiten, können Ähnlichkeiten zwischen Wörtern berechnet werden:
\begin{quote}
Distributional methods for meaning similarity are based on the observation that similar words occur in similar contexts and measure similarity based on patterns of word occurrence in large corpora [...]. More precisely, they represent words, or any other target linguistic elements, as high-dimensional vectors, where the dimensions represent context features.\\
Semantic relatedness is assessed by comparing vectors, leading, for example, to determine that \emph{car} and \emph{vehicle} are very similar in meaning, since they have similar contextual distributions. Despite the appeal of these methods, modeling words in isolation has limited applications and ideally we want to model semantics beyond word level by representing the meaning of phrases or sentences.
\end{quote}

Die Möglichkeit zu einem Wort die semantischen Nachbarn zu finden, wie es uns durch Dissect ermöglicht ist, nutzen wir für das Finden von Übersetzungskandidaten. In einem weiteren Schritt nutzen wir die Ähnlichkeitsmasse zwischen den Wörtern der einen Sprachen und denen der anderen Sprache. Dieses Mass verwenden wir in gewissem Sinn als Übersetzungsmodell.
Ein weiteres Ähnlichkeitsmass, also jenes zwischen den gefundenen Übersetzungskandidaten und dem Eingabesatz -- der semantisch auch dem Zielsatz entsprechen sollte -- nutzen wir in einer ähnlichen Weise wie das Sprachmodell in der konventionellen statistikbasierten maschinellen Übersetzung, ausser dass bei uns nur Schlüsse zur semantischer Komponente und nicht zu derjenigen der Wohlgeformtheit gezogen werden. Diese beiden Masse werden zu einem Score verrechnet, der die Sortierung nach den besten Kandidaten ermöglicht.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Aufbau des Inputs}
\label{cha:input}
Das Programm \verb+create_input_data.py+ berechnet aus einem zeilenweise alignierten parallelen Text am Beispiel des Sprachpaares Deutsch--Englisch folgende Dateien:
\begin{itemize}
\item \verb+de-words.row+ enthält die Wörter des deutschen Textes in Kleinbuchstaben. Die Liste ist gefiltert nach Stoppwörtern:
\begin{verbatim}
kosovo-krieg_de
wiederaufnahme_de
bekannt_de
vorbildlicher_de
...
\end{verbatim}
\item \verb+en-words.row+ ist die entsprechende Liste für die englischen Wörter:
\begin{verbatim}
clean_en
based_en
possible_en
resumption_en
...
\end{verbatim}
\item \verb+de_en-words.col+ besteht aus dem Inhalt der vorherigen beiden Dateien. Diese Liste soll für alle verwendeten Matrizen eines Projektes die Vektordimensionen definieren:
\begin{verbatim}
kosovo-krieg_de
wiederaufnahme_de
bekannt_de
vorbildlicher_de
clean_en
based_en
possible_en
resumption_en
...
\end{verbatim}
\item \verb+en_en-de.sm+ ist die sparse Matrix, die die Wörter auf Englisch mit ihren Kontextwörtern in beiden Sprachen beinhält. Die dritte Stelle gibt an, wie oft sich die beiden Wörter begegnen. 
\begin{verbatim}
art_en war_en 4
war_en recognised_en 4
art_en krieg_de 4
based_en clean_en 1
...
\end{verbatim}
\item \verb+de_de-en.sm+ ist die entsprechnede Matrix für die deutschen Wörter:
\begin{verbatim}
bekannt_de geschieht_de 1
krieg_de art_en 4
geschieht_de model_en 1
krieg_de model_en 4
...
\end{verbatim}
\end{itemize}

Aus diesen Dateien werden die gepickelten Dateien erstellt:
\begin{itemize}
\item \verb+de_de-en.pkl+ mit den Zeilen \verb+en-words.row+ und \\Spalten \verb+de_en-words.col+
\item \verb+en_en-de.pkl+ mit den Zeilen \verb+de-words.row+ und \\Spalten \verb+de_en-words.col+
\end{itemize}

Diese gepickelten Matrixdateien werden zusammen mit der Dimensionendatei \verb+de_en-words.col+ ans Programm \verb+besttranslations.py+ weitergegeben und dort eingelesen, bzw. beim Erstellen der Satzmatrix gebraucht.

Die Aufteilung der Wortvektoren in eine Matrix pro Sprache ist ein entscheidender Teil der Implementierung, da dadurch auf saubere Weise verhindert werden kann, dass Kandidaten in der ungewünschten Sprache durch Dissect gefunden. In einem ersten Aufbau wurden diese ungewünschten Wörter nach Abgleich des Sprachtags bestraft, d.\,h. ihr Ähnlichkeitswert auf 0.0 gesetzt. Dabei bestand die Gefahr, dass für manche Wörter in den x ähnlichsten Wörtern nur unerwünschte Kandidaten gefunden wurden und die dann allesamt bestraft wurden, wodurch schliesslich für diese Wörter nichts Brauchbares gefunden wurde.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Praxis}
\label{cha:praxis}
Die Programme sind stark parametrisierbar und es lassen sich die Sprachwahl, die zu verwendenden Dateien und auch Parameter zur Verarbeitung und zum Output als Argumente setzen.

In \verb+parameters.py+ lassen sich die Defaultwerte langfristig festlegen, wie zum Beispiel die Anzahl der Sätze, die zur Berechnung verwendet werden sollen oder die Anzahl der angezeigten Übersetzungen.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Evaluation}
\label{cha:evaluation}

\hspace{-6cm}\begin{tikzpicture}
    \begin{axis}[
        width  = 18cm,
        height = 8cm,
        major x tick style = transparent,
        ybar=2*\pgflinewidth,
        bar width=14pt,
        ymajorgrids = true,
        ylabel = {Gute Vorschläge (\%)},
        symbolic x coords={150k,100k,50k,30k,20k,10k,5k},
        xtick = data,
        scaled y ticks = false,
        enlarge x limits=0.07, % balkenbreite
        ymin=0,
        legend cell align=left,
        legend style={
                at={(1,1.05)},
                anchor=south east,
                column sep=1ex
        }
    ]
        \addplot coordinates {(150k, 49.3) (100k,44) (50k,52) (30k,56) (20k,58.7) (10k,54.7) (5k,42.7)};%de-en surf
        \addplot coordinates {(150k, 5.3) (100k,13.3) (50k,14.3)  (20k,0) (10k,0) (5k,16)};%de-en lemm

        \addplot coordinates {(150k, 65.6) (100k,67.2) (50k,64.1) (30k,71.9) (20k,70.3) (10k,64.1) (5k,57.8)};%en-de surf
        \addplot coordinates {(150k, 14.1) (100k,12.5) (50k,14.1)  (20k,0) (10k,0) (5k,20.3)};%en-de lemm

        \legend{de$\rightarrow$en Oberflächenformen,de$\rightarrow$en Lemmatisierung,en$\rightarrow$de Oberflächenformen,en$\rightarrow$de Lemmatisierung}
    \end{axis}
\end{tikzpicture}

\section{Übersetzungskandidaten EN--DE mit 30\,000 Trainingssätzen über Wortoberflächen}
\hspace{-4cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
sitting                 & sitzung (0.36) & 23.50 (0.29) & 00.05 (0.28) \\ %Y
\emph{opened}                  & harmonisierungsamt (0.16) & beginn (0.11) & wurde (0.10) \\ % not quite
minutes                 & protokoll (0.38) & minuten (0.35) & abstimmungsergebnis (0.25) \\ %Y
\emph{previous}                & vorredner (0.27) & wurde (0.16) & herr (0.14) \\ % wrong PoS 
sitting                 & vorangegangenen (0.40) & protokoll (0.38) & sitzung (0.37) \\ %Y
\emph{were}                    & vorangegangenen (0.44) & protokoll (0.40) & genehmigt (0.39) \\
approved                & angenommen (0.21) & angenommenen (0.18) & wurde (0.15) \\ %Y
President               & präsident (0.31) & herr (0.30) & präsidentin (0.28) \\ %Y
\emph{welcomed}                & präsidentin (0.26) & präsident (0.24) & kommissionspräsident (0.23) \\
adoption                & annahme (0.22) & hinblick (0.16) & betreffend (0.16) \\ %Y
\emph{euro}                    & präsident (0.25) & duisenberg (0.21) & kollegen (0.21) \\
Latvia                  & lettland (0.25) & estland (0.22) & ostsee-anrainerstaaten (0.18) \\ %Y
January                 & 1. (0.42) & januar (0.40) & Übergangsbestimmungen (0.25) \\ %Y
expressed               & ausdruck (0.25) & zustimmung (0.22) & wurde (0.20) \\ %Y
Parliament              & parlament (0.36) & parlaments (0.35) & rechtzeitigen (0.26) \\ %Y
solidarity              & solidarität (0.38) & ausdruck (0.23) & mitgefühls (0.21) \\ %Y
victims                 & opfer (0.32) & ausdruck (0.22) & wurde (0.17) \\ %Y
storms                  & stürme (0.28) & sturm (0.18) & abgeordnete (0.14) \\ %Y
President               & herr (0.30) & präsident (0.30) & präsidentin (0.27) \\ %Y
\emph{spoke}                   & präsidenten (0.32) & präsident (0.29) & präsidentin (0.27) \\
\emph{UN}                      & abgeordnete (0.21) & darauf (0.20) & tun (0.20) \\
conference              & konferenz (0.31) & regierungskonferenz (0.29) & möchte (0.25) \\ %Y
\emph{future}                  & darauf (0.23) & unsere (0.23) & ganz (0.23) \\
Syria                   & syrien (0.30) & volksabstimmungen (0.21) & präsident (0.21) \\ %Y
\emph{open}                    & möchte (0.27) & ganz (0.23) & darauf (0.23) \\
Geneva                  & genfer (0.27) & genf (0.26) & jahrestag (0.24) \\ %Y
January                 & januar (0.30) & 1. (0.24) & möchte (0.23) \\ %Y
President               & herr (0.28) & präsident (0.27) & präsidentin (0.25) \\ %Y
\emph{commented}               & zurückgehalten (0.32) & presseberichte (0.25) & berichte (0.22) \\ % wrong Pos
press                   & presse (0.22) & gemacht (0.19) & erklärt (0.18) \\ %Y
reports                 & berichte (0.29) & berichten (0.27) & präsidentin (0.26) \\ %Y
accusations             & vorwürfe (0.25) & anklägerin (0.19) & gewissenhafter (0.17) \\ %Y
made                    & kollegen (0.26) & frau (0.25) & gemacht (0.24) \\ %Y
Romanian                & rumänischen (0.25) & vorwürfe (0.19) & liliana (0.15) \\ %Y
Prime                   & premierminister (0.37) & ministerpräsidenten (0.29) & präsidentin (0.25) \\ %Y
Minister                & premierminister (0.40) & ministerpräsident (0.30) & ministerpräsidenten (0.29) \\ %Y
Victor                  & victor (0.22) & emmanuel (0.21) & steuereintreibers (0.14) \\ %Y
\emph{Ponta}                   & premierminister (0.37) & zurückgehalten (0.31) & ministerpräsident (0.28) \\
Elmar                   & elmar (0.26) & präsident (0.22) & präsidentin (0.21) \\ %Y
Brok                    & brok (0.27) & präsident (0.27) & elmar (0.25) \\ %Y
deadline                & termin (0.19) & grundsatzabkommen (0.17) & frist (0.17) \\ %Y
tabling                 & interpretiert. (0.14) & vorlage (0.13) & us-regierung (0.12) \\ %Y (vorlage: good!)
amendments              & Änderungsanträge (0.31) & Änderungsanträgen (0.30) & eingebrachten (0.26) \\ %Y
\emph{was}                     & 12 (0.30) & Änderungsanträge (0.29) & 14 (0.28) \\
\emph{set}                     & wurden (0.21) & ansicht (0.20) & betrifft (0.19) \\
Tuesday                 & dienstag (0.27) & schlagzeile (0.16) & herald (0.16) \\ %Y
January                 & januar (0.29) & 26. (0.21) & 1. (0.21) \\ %Y
noon                    & 12.00 (0.32) & 12 (0.29) & findet (0.25) \\ %Y
vote                    & abstimmung (0.36) & bitte (0.26) & findet (0.25) \\ %Y
\emph{be}                      & 12.00 (0.34) & abstimmung (0.34) & verlegen (0.34) \\
held                    & möchte (0.25) & übrigen (0.21) & halten (0.20) \\ %Y
Wednesday               & mittwoch (0.36) & abstimmung (0.33) & bitte (0.24) \\ %Y
January                 & januar (0.33) & 1. (0.24) & 15. (0.22) \\ %Y
noon                    & 12.00 (0.44) & abstimmung (0.43) & findet (0.37) \\ %Y
\emph{appointments}            & wäre (0.26) & durchgefallen (0.23) & verpuffen (0.23) \\
be                      & minuten (0.32) & wäre (0.30) & wären (0.26) \\ %Y
\emph{deemed}                  & instrumentalisiert (0.17) & kriegsgerät (0.16) & kaste (0.16) \\
ratified                & ratifiziert (0.27) & ratifizierung (0.18) & symbolhafte (0.18) \\ %Y
were                    & minuten (0.32) & wäre (0.30) & wären (0.26) \\ %Y (good!)
\emph{objections}              & hätte (0.23) & könnte. (0.22) & wertpapierdienstleistungen (0.21) \\
approval                & hätte (0.26) & möchte (0.22) & zustimmung (0.21) \\ %Y
minutes                 & minuten (0.32) & protokoll (0.28) & hätte (0.23) \\ %Y
\emph{item}                    & folgt (0.34) & tagesordnung (0.29) & anfragen: (0.29) \\ % not quite
closed                  & geschlossen (0.47) & 1999-2000 (0.31) & 19.40 (0.31) \\ %Y
\hline
\end{tabular}\end{footnotesize}\\


%%%
\section{Übersetzungskandidaten DE--EN mit 10\,000 Trainingssätzen über Wortoberflächen}
\label{sec:evalDeEn10kSurf}


\section{Übersetzungskandidaten EN--DE mit 10\,000 Trainingssätzen über Wortoberflächen}
\label{sec:evalDeEn10kSurf}
\section{Übersetzungskandidaten EN--DE mit 10\,000 Trainingssätzen über Wortoberflächen}

\section{Innerhalb einer Sprache}
Die folgenden Beispiele zeigen, was passiert, wenn man innerhalb einer Sprache probiert zu übersetzen. Für die Semantik wurden die gleiche Art von Matrizen verwendet wie bei den zweisprachigen Versuchen, jedoch wurde für die Ausgangs- und Zielsprache -- die ja gleich sind -- dieselbe Matrix verwendet. Von einer Arbeitsweise rein in einer Sprache unterscheidet sich dieses Verfahren nur darin, dass in den Vektordimensionen noch die Wörter der anderen Sprache auftauchen. Der Einfluss sollte sich gering halten und es könnte höchstens erwartet werden, dass satzabhängige ähnliche Wörter gefunden werden.

\subsection{Englisch mit Oberflächenform (10\,000 Trainingssätze)}
\hspace{-0cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
The & & & \\
sitting                 & 8.40 (0.32) & 11.15 (0.32) & 8.14 (0.32) \\
opened                  & opened (0.25) & bosnia (0.19) & serbia (0.19) \\
at & & & \\
17.05 & & & \\
. & & & \\
The & & & \\
minutes                 & minutes (0.27) & sitting (0.21) & distributed (0.18) \\
of & & & \\
the & & & \\
previous                & previous (0.28) & speakers (0.17) & period (0.15) \\
sitting                 & sitting (0.38) & 8.40 (0.25) & 11.15 (0.25) \\
were                    & 8.40 (0.20) & 11.15 (0.20) & 8.14 (0.20) \\
approved                & approved (0.28) & adopted (0.17) & commission (0.16) \\
. & & & \\
The & & & \\
President               & ladies (0.28) & prodi (0.28) & reformist (0.28) \\
welcomed                & welcomed (0.28) & cut (0.18) & anti-racist (0.18) \\
the & & & \\
adoption                & adoption (0.29) & featuring (0.16) & nana (0.16) \\
of & & & \\
the & & & \\
euro                    & euro (0.30) & dollar (0.26) & interventionism (0.19) \\
by & & & \\
Latvia                  & inspiring (0.17) & surety (0.17) & re-read (0.17) \\
on & & & \\
1 & & & \\
January                 & january (0.33) & standardisation (0.19) & constructed (0.18) \\
2014. & & & \\
\hline
\end{tabular}\end{footnotesize}\\

Mit dem Beispiel von 'President', das nicht mehr gefunden wurde, haben wir einen Fall, der an die zweisprachige Evaluation erinnert, wo dieses Wort auch Schwierigkeiten ergab und die Vorschläge ähnlich waren.

Grosse Beachtung verdienen auch die verschiedenen Vorschläge für 'sitting': Einmal wurde korrekt wieder auf 'sitting' verwiesen mit Zahlausdrücken als Alternative, das andere Mal kamen nur die Zahlausdrücke.

Auch wenn sie hier nicht passen sind die Vorschläge 'serbia' und 'bosnia' interessant in ihrem gemeinsamen Vorkommen. Als gewünscht kann man die Alternative 'dollar' zu 'euro' bezeichnen, wo beide klar semantisch dem gleichen Feld angehören.

\subsection{Englisch mit Lemmatisierung (10\,000 Trainingssätze)}
\hspace{-0cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
The & & & \\
sitting                 & sitting (0.08) & anniversary (0.05) & declaration (0.05) \\
opened                  & open (0.08) & way (0.06) & go (0.06) \\
at & & & \\
17.05 & & & \\
. & & & \\
The & & & \\
minutes                 & go (0.12) & hold (0.12) & use (0.12) \\
of & & & \\
the & & & \\
previous                & pump (0.12) & squeeze (0.12) & distribute (0.12) \\
sitting                 & distribute (0.12) & go (0.11) & use (0.11) \\
were                    & concern (0.15) & something (0.15) & go (0.15) \\
approved                & concern (0.15) & something (0.14) & go (0.14) \\
. & & & \\
The & & & \\
President               & ending (0.07) & this (0.05) & noire (0.05) \\
welcomed                & welcome (0.08) & fact (0.05) & s (0.05) \\
the & & & \\
adoption                & adoption (0.08) & fact (0.06) & adopt (0.05) \\
of & & & \\
the & & & \\
euro                    & ending (0.07) & this (0.05) & noire (0.05) \\
by & & & \\
Latvia                  & ending (0.07) & this (0.05) & noire (0.05) \\
on & & & \\
1 & & & \\
January                 & ending (0.07) & this (0.05) & noire (0.05) \\
2014. & & & \\
\hline
\end{tabular}\end{footnotesize}\\

In diesem Beispiel wurden beim erstens Satz gute Vorschläge gebracht, der Rest lässt jedoch zu wünschen übrig.

Man kann sicherlich sagen, dass durch die Lemmatisierung die Relation von Wörtern zu ihrem Umfeld verloren gehen kann -- mehr als bei den Oberflächenformen -- und die Verarbeitung mehr einem Bag-of-words ähnelt. Dies reicht aber nicht zur Erklärung, wieso besonders der letzte Satz ein derart schlechtes Resultat brachte.

\subsection{Deutsch mit Oberflächenform (10\,000 Trainingssätze)}
\hspace{-4.5cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
Die & & & \\
Sitzung                 & sitzung (0.38) & 13.05 (0.35) & 19.50 (0.35) \\
wird                    & 13.05 (0.31) & 19.50 (0.31) & 17.30 (0.29) \\
um & & & \\
17.05 & & & \\
Uhr                     & 12.00 (0.38) & 13.05 (0.32) & 19.50 (0.32) \\
eröffnet               & eröffnet (0.25) & billigen (0.22) & tätigkeitsfeld (0.19) \\
. & & & \\
Das & & & \\
Protokoll               & protokoll (0.32) & protokolls (0.26) & montreal (0.19) \\
der & & & \\
vorangegangenen         & vorangegangenen (0.31) & mindestdauer (0.22) & erhoffe (0.22) \\
Sitzung                 & sitzung (0.25) & protokolls (0.23) & genehmigung (0.17) \\
wird                    & protokolls (0.21) & wiedergegeben (0.16) & genehmigung (0.16) \\
genehmigt               & genehmigt (0.30) & abgefaßt (0.23) & stahlunternehmen (0.21) \\
. & & & \\
Der & & & \\
Präsident              & herr (0.33) & präsident (0.26) & kollegen (0.23) \\
begrüßt               & begrüßt (0.25) & herr (0.19) & demokraten (0.15) \\
die & & & \\
Einführung             & einführung (0.28) & wirtschaft (0.15) & wurde (0.15) \\
des & & & \\
Euro                    & euro (0.27) & milliarden (0.24) & millionen (0.24) \\
als & & & \\
Währung                & währung (0.27) & wirtschaft (0.21) & a5-0073/1999 (0.20) \\
in & & & \\
Lettland                & Übergangsbestimmungen (0.22) & entschiedenheit (0.17) & geldfälschung (0.14) \\
am & & & \\
1.                      & 1. (0.33) & Übergangsbestimmungen (0.28) & programmvorlage (0.19) \\
Januar                  & januar (0.25) & Übergangsbestimmungen (0.24) & 1. (0.23) \\
2014.                   & Übergangsbestimmungen (0.22) & entschiedenheit (0.17) & geldfälschung (0.14) \\
\hline
\end{tabular}\end{footnotesize}\\

Hier sind im Grossen und Ganzen gute Vorschläge zu finden. Das Trippel aus 'euro', 'milliarden' und 'millionen' zeigt, dass auch semantisch ähnliche Wörter gefunden werden können. Schön ist auch dass wie mit 'protokoll' und 'protokolls' Formen des gleichen Wortes gefunden werden konnten. Das könnte bedeuten, dass sich auch die verschiedenen Formen eines Wortes annähern.

\subsection{Deutsch mit Lemmatisierung (10\,000 Trainingssätze)}
\hspace{-2.7cm}\begin{footnotesize}\begin{tabular}{|llll|}
\hline
Die & & & \\
Sitzung                 & sitzung (0.13) & durchführen (0.10) & Änderungsantrag (0.10) \\
wird                    & müssen (0.10) & schnell (0.10) & dürfen (0.10) \\
um & & & \\
17.05 & & & \\
Uhr                     & sitzung (0.09) & uhr (0.09) & unterbrechen (0.08) \\
eröffnet               & eröffnen (0.09) & aufnehmen (0.09) & einsetzen (0.09) \\
. & & & \\
Das & & & \\
Protokoll               & protokoll (0.13) & aufnehmen (0.09) & Änderungsantrag (0.09) \\
der & & & \\
vorangegangenen         & vorangegangen (0.11) & durchführen (0.09) & Änderungsantrag (0.09) \\
Sitzung                 & sitzung (0.11) & durchführen (0.10) & aufnehmen (0.09) \\
wird                    & müssen (0.10) & schnell (0.10) & dürfen (0.10) \\
genehmigt               & genehmigen (0.09) & müssen (0.08) & dürfen (0.08) \\
. & & & \\
Der & & & \\
Präsident              & herr (0.10) & präsident (0.08) & kommissar (0.07) \\
begrüßt               & herr (0.08) & begrüßen (0.08) & fraktion (0.07) \\
die & & & \\
Einführung             & einführung (0.08) & kommission (0.07) & weit (0.07) \\
des & & & \\
Euro                    & million (0.09) & euro (0.08) & gering (0.07) \\
als & & & \\
Währung                & währung (0.08) & wirtschaft (0.07) & einführung (0.06) \\
in & & & \\
Lettland                & Übergangsbestimmung (0.10) & gesamtumfang (0.06) & entschiedenheit (0.05) \\
am & & & \\
1.                      & 1. (0.10) & januar (0.06) & jahr (0.06) \\
Januar                  & januar (0.08) & kommission (0.07) & erst (0.07) \\
2014.                   & Übergangsbestimmung (0.10) & gesamtumfang (0.06) & entschiedenheit (0.05) \\
\hline
\end{tabular}\end{footnotesize}\\

Mit deutsch als Ausgangs- und Zielsprache ist die Lemmatisierung nicht ein solches Hindernis, wie auf Englisch. Deutlich mehr Vorschläge lassen sich mit semantischen Feldern erklären und die Grundform des Wortes erscheint auch oft in den ersten beiden Vorschlägen.

Interessant ist auch der Zusammenhang zwischen 'werden' und 'müssen'. Beide kommen als Hilfs- bzw. als Modalverb in einem ähnlichen Zusammenhang vor und durch die Lemmatisierung geht ihre Restriktion der untergeordneten Verbform verloren. Sie können wirklich als ähnlich bezeichnet werden.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Schluss}
\label{cha:schluss}

sehr häppy. es klappt. 

speziell: lemmatisierung. für englisch offenbar nicht gut. (wortarten bleiben erhalten, was macht es also bei englisch für einen unterschied?



Versuchsreihen mit ähnlicheren Sprachen?

hapax legomena aus den vektordimensionen entfernen?

smoothing

anderes korpus? das hier ist hochgradig domänenspezifisch. opensubs?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plain-de}     % For German
\bibliography{seminar}
\addcontentsline{toc}{chapter}{Literaturverzeichnis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listoffigures
\addcontentsline{toc}{chapter}{Abbildungsverzeichnis}
\end{document}
